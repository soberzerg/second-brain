# Применение RAG систем к проектам

**Источник:** [[RAG from basics to advanced]]
**Дата:** 2026-01-02

---

## Ключевые концепции RAG

### Pipeline Overview

```
Documents → Chunking → Embeddings → Vector DB
                                        ↓
User Query → Embedding → Similarity Search → Retrieve
                                                ↓
                                        Context + Query → LLM → Answer
```

### Основные компоненты

1. **Document Processing**
   - Загрузка документов
   - Chunking (разбиение на части)
   - Metadata extraction

2. **Embedding Generation**
   - Векторное представление текста
   - Модели: OpenAI, Cohere, open-source

3. **Vector Storage**
   - Векторная БД: Pinecone, Weaviate, Qdrant, Chroma
   - Индексирование для быстрого поиска

4. **Retrieval**
   - Semantic search по векторам
   - Top-K results
   - Reranking для улучшения релевантности

5. **Generation**
   - LLM с контекстом из retrieval
   - Грounded ответы (с источниками)

---

## Применение к AGIents.pro

### Use Case: Knowledge Base для агентов

**Проблема:**
Агент должен знать специфику бизнеса клиента (услуги, цены, правила) без hardcoding.

**Решение: RAG система**

#### Архитектура

```
[Client Docs] → [Chunking] → [Embeddings] → [Vector DB]
                                                ↓
[User Query] → [Agent Reasoning] → [Semantic Search]
                                         ↓
                                    [Top-K chunks]
                                         ↓
                                [LLM + Context] → [Answer]
```

#### Implementation для Amaks

**Источники данных:**
- Описания услуг (лечебные программы)
- Прайс-листы
- FAQ
- Правила санатория
- Описания номеров

**Chunking Strategy:**
- Размер chunk: 500-1000 tokens
- Overlap: 100-200 tokens
- Сохранение структуры (заголовки, секции)

**Embedding Model:**
- OpenAI `text-embedding-3-small` (1536 dimensions)
- Или: Cohere embed-multilingual-v3 (для Russian)

**Vector DB:**
- Начать с: Qdrant (self-hosted)
- Альтернатива: Chroma (embedded)
- Production: Pinecone или Weaviate

**Retrieval:**
- Top-K: 5-10 chunks
- Similarity threshold: 0.7+
- Reranking: Cohere rerank или cross-encoder

#### Prompt Template с RAG

```
System: You are a санаторий consultant.
Use the context below to answer questions.
If context doesn't contain answer, say so.

Context:
{retrieved_chunks}

User Question: {question}

Answer based on context, cite sources:
```

---

## Применение к Amaks (текущий проект)

### Текущая реализация

**Что уже работает:**
- _[Заполнить после проверки с клиентом]_

**Что можно улучшить:**

#### 1. Advanced Chunking

**Проблема:** Простое разбиение теряет контекст

**Решение:**
- Recursive chunking по структуре документа
- Semantic chunking (разбиение по смыслу)
- Parent-child chunks (малые chunks + большой parent для контекста)

#### 2. Metadata Filtering

**Проблема:** Релевантность страдает без фильтрации

**Решение:**
```python
metadata = {
    "source": "price_list",
    "sanatorium": "Amaks #1",
    "category": "medical_programs",
    "date_updated": "2026-01-01"
}
```

**Query с фильтром:**
```python
results = vector_db.search(
    query_embedding,
    filter={
        "sanatorium": "Amaks #1",
        "category": "medical_programs"
    },
    top_k=5
)
```

#### 3. Hybrid Search

**Проблема:** Semantic search может пропустить exact matches

**Решение: Hybrid (Dense + Sparse)**
- Dense: vector embeddings (семантика)
- Sparse: BM25, TF-IDF (keywords)
- Combine scores: 0.7 * dense + 0.3 * sparse

#### 4. Reranking

**Проблема:** Top-K может быть не самым релевантным

**Решение:**
- Retrieve top-20
- Rerank to top-5
- Models: Cohere rerank, cross-encoder

---

## Применение к AI-код-ревью системе

### Use Case: Code Pattern Search

**Проблема:**
Найти похожие code patterns для code review suggestions.

**Решение: RAG для кода**

#### Специфика кода

**Document = Code file/function**

**Chunking:**
- Function-level chunks (1 функция = 1 chunk)
- Class-level chunks
- Сохранение imports, dependencies

**Embeddings:**
- Code-specific models: CodeBERT, GraphCodeBERT
- Или: OpenAI embeddings (работают и для кода)

**Metadata:**
```python
{
    "language": "go",
    "file_path": "services/agent/executor.go",
    "function_name": "Execute",
    "complexity": "medium",
    "lines": 45
}
```

**Query:**
"Find similar error handling patterns"

**Retrieved:**
```go
// services/integration/http.go:123
func (h *HTTPClient) Call() error {
    resp, err := h.client.Do(req)
    if err != nil {
        return fmt.Errorf("http call failed: %w", err)
    }
    defer resp.Body.Close()
    // ...
}
```

---

## Best Practices из статьи

### 1. Chunking

**Recommendations:**
- 500-1000 tokens per chunk
- 10-20% overlap
- Preserve semantic boundaries (paragraphs, sections)

**For AGIents:**
- Документация клиента: по sections
- FAQ: по вопросам (1 Q&A = 1 chunk)
- Прайсы: по категориям услуг

### 2. Embeddings

**Model Selection:**
- English: OpenAI, Cohere
- Multilingual: Cohere multilingual, e5-multilingual
- Russian-specific: ruBERT, sbert-russian

**For AGIents:**
- Start: OpenAI text-embedding-3-small (дешево, быстро)
- Later: Experiment с multilingual models

### 3. Retrieval

**Parameters to tune:**
- Top-K: 3-10 (зависит от use case)
- Similarity threshold: 0.7-0.8
- Max context length: 2K-4K tokens

**For AGIents:**
- Top-K: 5 (баланс релевантности и контекста)
- Threshold: 0.75
- Если nothing relevant → fallback to general knowledge

### 4. Prompting

**Template:**
```
Context: {retrieved_docs}

Question: {user_query}

Instructions:
- Answer based on context
- If unsure, say "I don't have this information"
- Cite sources: [Source: doc_name]
```

---

## Implementation для AGIents MVP

### Week 1-2: Basic RAG

**Components:**
- Document uploader (клиент загружает docs)
- Simple chunking (fixed size)
- OpenAI embeddings
- Qdrant vector DB (Docker)
- Simple retrieval (top-5)

**Test:** Amaks FAQ

### Week 3-4: Advanced RAG

**Improvements:**
- Metadata filtering (по sanatorium, категориям)
- Hybrid search (semantic + keyword)
- Reranking
- Structured output (с источниками)

**Test:** Full Amaks knowledge base

### Month 2: Production RAG

**Features:**
- Incremental updates (не rebuild всего)
- Multi-tenant (изоляция данных клиентов)
- Analytics (какие вопросы, какие chunks используются)
- Monitoring (latency, relevance scores)

---

## Metrics & Evaluation

### Retrieval Metrics

**Relevance:**
- Precision@K: сколько из top-K relevant
- Recall@K: сколько relevant было найдено
- MRR (Mean Reciprocal Rank): позиция первого relevant

**For AGIents:**
- Target: Precision@5 > 80%
- Target: Recall@5 > 70%

### Generation Metrics

**Groundedness:**
- Answer supported by retrieved context?
- Hallucination rate < 5%

**Answer Quality:**
- Correctness (human eval)
- Completeness
- Citation accuracy

### Business Metrics

**User Satisfaction:**
- CSAT score
- Thumbs up/down on answers
- Escalation rate (когда агент не смог ответить)

---

## Challenges & Solutions

### Challenge 1: Multilingual (Russian + English)

**Solution:**
- Cohere multilingual embeddings
- Или: separate indexes для разных языков
- Translation layer если нужно

### Challenge 2: Outdated Information

**Solution:**
- Timestamp на chunks
- Регулярные updates (webhook от клиента?)
- Версионирование knowledge base

### Challenge 3: Cost

**Solution:**
- Кеширование частых queries
- Меньшие embedding models где возможно
- Incremental indexing (не rebuild всего)

### Challenge 4: Latency

**Solution:**
- Async retrieval
- Precompute embeddings
- Efficient vector DB (Qdrant быстрее Chroma)

---

## Tech Stack Recommendation

### MVP (Q1)
- **Vector DB:** Qdrant (self-hosted Docker)
- **Embeddings:** OpenAI text-embedding-3-small
- **Chunking:** LangChain RecursiveTextSplitter
- **Retrieval:** Qdrant similarity search

### Production (Q2+)
- **Vector DB:** Qdrant cluster или Pinecone
- **Embeddings:** Experiment с Cohere multilingual
- **Reranking:** Cohere rerank
- **Monitoring:** Custom metrics + alerts

---

## Next Steps

### Week 1 (Сейчас)
- [x] Изучить RAG from basics to advanced
- [ ] POC: простой RAG для Amaks FAQ
- [ ] Измерить relevance на 20-30 вопросах

### Week 2
- [ ] Integrate в AGIents архитектуру
- [ ] Metadata filtering
- [ ] Test на полной базе Amaks

### Week 3-4
- [ ] Advanced features (hybrid search, reranking)
- [ ] Multi-tenant support
- [ ] Beta test с 5-м санаторием

---

## Связанные материалы

- [[RAG from basics to advanced]] - исходная статья
- [[MVP Specification]] - RAG как часть MVP
- [[Кейс Amaks]] - применение RAG
- [[Implementation Details]] - технические детали Amaks

---

*Создано: 2026-01-02*
*Статус: Конспект готов, требуется POC*
